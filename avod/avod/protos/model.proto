package avod.protos;

import "avod/protos/layers.proto";

// Message for configuring the DetectionModel.
message ModelConfig {

    // Model name used to run either RPN or AVOD
    optional string model_name = 1 [default = 'avod_model'];

    // Checkpoint name
    optional string checkpoint_name = 2 [default = 'detection_model'];

    optional PathsConfig paths_config = 3;
    required InputConfig input_config = 4;
    optional RpnConfig rpn_config = 5;
    optional AvodConfig avod_config = 6;
    optional RetinaNetConfig retinanet_config = 15;
    optional bool use_retinanet = 16 [default=false];

    // Label smoothing epsilon
    required float label_smoothing_epsilon = 7;

    // Expand proposals lengths along x and z for larger context region (in m)
    // (0.0 - 1.0 recommended)
    required float expand_proposals_xz = 8;

    // Global path drop (p_keep_img, p_keep_bev)
    // To disable path drop, set both to 1.0
    repeated float path_drop_probabilities = 9;

    // To keep all the samples including the ones without anchor-info
    // i.e. labels during training
    required bool train_on_all_samples = 10;

    // To keep all the samples including the ones without anchor-info
    // i.e. labels during validation
    required bool eval_all_samples = 11;

    // Layer configurations
    required LayersConfig layers_config = 12;

    // Loss configurations
    required LossConfig loss_config = 13;
}

message PathsConfig {
    // Checkpoint dir
    optional string checkpoint_dir = 1;

    // Log dir (no underscore to match tensorboard)
    optional string logdir = 2;

    // Directory to save predictions
    optional string pred_dir = 3;
}

message InputConfig {
    // Bev dimensions
    optional int32 bev_dims_h = 1 [default = 700];
    optional int32 bev_dims_w = 2 [default = 800];
    optional int32 bev_depth = 3 [default = 6];

    // Image dimensions
    optional int32 img_dims_h = 4 [default = 480];
    optional int32 img_dims_w = 5 [default = 1590];
    optional int32 img_depth = 6 [default = 3];
}

message RpnConfig {
    // RPN proposal ROI crop size
    required int32 rpn_proposal_roi_crop_size = 1;

    // RPN proposal ROI fusion method, one of ['mean', 'concat']
    required string rpn_fusion_method = 2;

    // RPN Non-max suppression boxes during training
    required int32 rpn_train_nms_size = 3;

    // RPN Non-max suppression boxes during testing
    required int32 rpn_test_nms_size = 4;

    // RPN NMS IoU threshold
    required float rpn_nms_iou_thresh = 5;

    // WZN: add sparse pooling layer in the network
    optional bool rpn_use_sparse_pooling = 6 [default=false];
    optional bool rpn_sparse_pooling_use_batch_norm = 7 [default=false];
    optional bool rpn_sparse_pooling_conv_after_fusion = 8 [default=true];
    optional bool rpn_sparse_pooling_after_vgg = 9 [default=false];
    optional bool rpn_dual_sparse_pooling_after_vgg = 10 [default=false];
}

message AvodConfig {
    // AVOD Proposal ROI crop size
    required int32 avod_proposal_roi_crop_size = 1;

    // Positive selection, one of ['corr_cls', 'not_bkg']
    required string avod_positive_selection = 3;

    // AVOD Non-max suppression boxes
    required int32 avod_nms_size = 4;

    // AVOD NMS IoU threshold
    required float avod_nms_iou_thresh = 5;

    // AVOD bounding box representation, one of ['box_3d', 'box_8c']
    required string avod_box_representation = 6;
}

message RetinaNetConfig {

    required float nms_iou_thresh = 1;
    optional float nms_filtered_score = 2 [default=0.05];
    required int32 nms_size = 3;
    optional int32 refine_stage_num = 4 [default = 0];
    repeated float refine_pos_iou_thresh = 10;
    repeated float refine_neg_iou_thresh = 11;
    // YLY: add sparse pooling layer in the network
    optional bool use_sparse_pooling = 6 [default=false];
    optional string use_pyramid_level_at_SHPL = 9 [default='P2'];
    optional bool add_h = 13 [default=false];
    optional bool add_angle = 14 [default=false];

}

message LossConfig {
    // RPN/AVOD Regression loss weight
    required float reg_loss_weight = 1;
    // RPN/AVOD Classification loss weight
    required float cls_loss_weight = 3;
    // AVOD angle vector loss weight
    optional float ang_loss_weight = 2 [default=0.0];
    optional float h_loss_weight = 6 [default=0.0];
    //All about refine is optinal..
    repeated float refine_cls_loss_weight = 4;
    repeated float refine_reg_loss_weight = 5;
    repeated float refine_ang_loss_weight = 7;
    repeated float refine_h_loss_weight = 8;
}

