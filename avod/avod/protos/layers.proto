package avod.protos;

// Message for configuring Model Layer params.
message LayersConfig {

    required FeatureExtractor bev_feature_extractor = 1;
    required FeatureExtractor img_feature_extractor = 2;

    //for models
    optional RPNLayersConfig rpn_config = 3;
    optional AVODLayersConfig avod_config = 4;
    optional RetinaNetLayersConfig retinanet_config = 5;
}


message FeatureExtractor {
    oneof feature_extractor {

        VGGLayersConfig bev_vgg = 1;
        VGGLayersConfig img_vgg = 2;

        PyramidLayersConfig img_vgg_pyr = 3;
        PyramidLayersConfig bev_vgg_pyr = 4;

        ResnetFPNLayersConfig bev_resnet_fpn = 5;
        ResnetFPNLayersConfig img_resnet_fpn = 6;

    }
}
//
// Feature Extractor 
//
message VGGLayersConfig {
    // Conv layer 1 [repeat, num filter]
    repeated int32 vgg_conv1 = 1;

    // Conv layer 2 [repeat, num filter]
    repeated int32 vgg_conv2 = 2;

    // Conv layer 3 [repeat, num filter]
    repeated int32 vgg_conv3 = 3;

    // Conv layer 4 [repeat, num filter]
    repeated int32 vgg_conv4 = 4;

    // Upsampling multiplier
    required int32 upsampling_multiplier = 5;

    // L2 norm weight decay
    optional float l2_weight_decay = 6 [default = 0.0005];
}

message PyramidLayersConfig {
    // Conv layer 1 [repeat, num filter]
    repeated int32 vgg_conv1 = 1;

    // Conv layer 2 [repeat, num filter]
    repeated int32 vgg_conv2 = 2;

    // Conv layer 3 [repeat, num filter]
    repeated int32 vgg_conv3 = 3;

    // Conv layer 4 [repeat, num filter]
    repeated int32 vgg_conv4 = 4;

    // L2 norm weight decay
    optional float l2_weight_decay = 6 [default = 0.0005];
}

message ResnetFPNLayersConfig{
    // using which pyramid levels ?
    required string resnet_name = 1;
    repeated string pyramid_levels = 2; 
    required float weight_decay = 3 [default = 0.0005];
    optional bool use_p5_at_p6 = 4 [default=true];
    optional bool use_relu_at_fusion = 5 [default=false];
    optional bool load_from_pretrained = 6 [default=false];
}

//
// Model
//
message RPNLayersConfig {
    // Anchor predictor layer configs
    // classification fc layer size
    required int32 cls_fc6 = 1;
    required int32 cls_fc7 = 2;

    // Regression fc layer size
    required int32 reg_fc6 = 3;
    required int32 reg_fc7 = 4;

    // L2 weight decay
    required float l2_weight_decay = 6;

    // Dropout probability - the probabilit that a neuron's
    // output is kept during dropout
    optional float keep_prob = 5 [default = 0.5];
}

message AVODLayersConfig{
    oneof fc_layers {
        BasicFcLayers basic_fc_layers = 1;
        FusionFcLayers fusion_fc_layers = 2;
    }
}

message BasicFcLayers {
    required int32 num_layers = 1;
    repeated int32 layer_sizes = 2;

    // L2 weight decay
    required float l2_weight_decay = 3;

    // Dropout keep probability
    required float keep_prob = 4;

    // Fusion method ('mean', 'concat')
    required string fusion_method = 5;
}

message FusionFcLayers {

    required int32 num_layers = 1;
    repeated int32 layer_sizes = 2;

    // L2 weight decay
    required float l2_weight_decay = 3;

    // Dropout keep probability
    required float keep_prob = 4;

    // Fusion method ('mean', 'concat')
    required string fusion_method = 5;

    // Fusion type (early, late, deep)
    required string fusion_type = 6;
}

message RetinaNetLayersConfig {
    optional string test = 1;
}
